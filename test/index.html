<!DOCTYPE html>
<html lang="en">
<head>
  <!-- put inside <head> -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&family=Source+Code+Pro:wght@400;600&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="styles.css">
  <meta charset="UTF-8" />
  <title>Realtime LLM Stream Demo</title>
  <style>
    body { font-family: sans-serif; margin: 2em; }
    textarea { width: 100%; height: 100px; }
    pre { background: #f4f4f4; padding: 1em; border-radius: 8px; white-space: pre-wrap; }
  </style>
</head>
<body>
  <div class="app">
    <div class="sidebar">
      <div class="brand">
        <div class="logo">AI</div>
        <div>
          <div class="app-title">My AI Assistant</div>
          <div class="app-desc">Fast streaming answers</div>
        </div>
      </div>

      <div class="history" id="history"></div>
    </div>

    <div class="main">
      <div class="messages" id="messages">
        <!-- chat messages here -->
        <div class="message assistant">
          <div class="response" id="response"></div>
        </div>
      </div>

      <div class="composer">
        <textarea id="prompt" placeholder="Ask the assistant anything..."></textarea>
        <button id="send">Send</button>
      </div>
    </div>
  </div>
  <script>
    const messages = [
      { role: "system", content: "You are a helpful assistant." }
    ];

    async function readLLMStream(response, onChunk) {
      const decoder = new TextDecoder("utf-8");
      const reader = response.body.getReader();
      let buffer = "";
      let collectedMessages = [];

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;
        buffer += decoder.decode(value, { stream: true });

        const lines = buffer.split("\n");
        buffer = lines.pop(); // keep last partial line

        for (const line of lines) {
          const trimmed = line.trim();
          if (!trimmed.startsWith("data:")) continue;
          const jsonPart = trimmed.slice("data:".length).trim();
          if (jsonPart === "[DONE]") {
            // Stream finished: append full assistant message to memory
            const fullReply = collectedMessages.join("");
            messages.push({ role: "assistant", content: fullReply });
            console.log("Memory updated:", messages);
            return;
          }

          try {
            const parsed = JSON.parse(jsonPart);
            const chunkMessage = parsed?.choices?.[0]?.delta?.content ?? "";
            if (chunkMessage) {
              collectedMessages.push(chunkMessage);
              onChunk(chunkMessage);
            }
          } catch {
            // ignore parse errors
          }
        }
      }
    }

    document.getElementById("send").onclick = async () => {
      const prompt = document.getElementById("prompt").value;
      const responseBox = document.getElementById("response");
      responseBox.textContent += "\nYou: " + prompt + "\n";
      responseBox.textContent += "CopenAI: ";

      // Add user's message to memory
      messages.push({ role: "user", content: prompt });

      const response = await fetch("/api/generate", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ messages })
      });

      await readLLMStream(response, chunk => {
        responseBox.textContent += chunk;
      });
    };
  </script>
</body>
</html>